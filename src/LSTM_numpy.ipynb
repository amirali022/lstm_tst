{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 866, Char size: 32\n"
     ]
    }
   ],
   "source": [
    "data = \"\"\"To be, or not to be, that is the question: Whether \\\n",
    "'tis nobler in the mind to suffer The slings and arrows of ou\\\n",
    "trageous fortune, Or to take arms against a sea of troubles A\\\n",
    "nd by opposing end them. To die—to sleep, No more; and by a s\\\n",
    "leep to say we end The heart-ache and the thousand natural sh\\\n",
    "ocks That flesh is heir to: 'tis a consummation Devoutly to b\\\n",
    "e wish'd. To die, to sleep; To sleep, perchance to dream—ay, \\\n",
    "there's the rub: For in that sleep of death what dreams may c\\\n",
    "ome, When we have shuffled off this mortal coil, Must give us\\\n",
    " pause—there's the respect That makes calamity of so long lif\\\n",
    "e. For who would bear the whips and scorns of time, Th'oppres\\\n",
    "sor's wrong, the proud man's contumely, The pangs of dispriz'\\\n",
    "d love, the law's delay, The insolence of office, and the spu\\\n",
    "rns That patient merit of th'unworthy takes, When he himself \\\n",
    "might his quietus make\"\"\".lower()\n",
    "\n",
    "chars = set( data)\n",
    "\n",
    "data_size, char_size = len( data), len( chars)\n",
    "\n",
    "print( f\"Data Size: { data_size}, Char size: { char_size}\")\n",
    "\n",
    "char_to_idx = { c: i for i, c in enumerate( chars)}\n",
    "idx_to_char = { i: c for i, c in enumerate( chars)}\n",
    "\n",
    "train_X, train_y = data[ :-1], data[ 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode( text):\n",
    "\toutput = np.zeros( ( char_size, 1))\n",
    "\toutput[ char_to_idx[ text]] = 1\n",
    "\n",
    "\treturn output\n",
    "\n",
    "def initWeight( input_size, output_size):\n",
    "\treturn np.random.uniform( -1, 1, ( output_size, input_size)) * np.sqrt( 6 / ( input_size + output_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Activation functions\n",
    "\n",
    "> when the derivative functions are called later in the code, they will be called on variables that have already had tanh of sigmoid applied. For this reason, the following functions are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid( input, derivative = False):\n",
    "\tif derivative:\n",
    "\t\treturn input * ( 1 - input)\n",
    "\t\n",
    "\treturn 1 / ( 1 + np.exp( -input))\n",
    "\n",
    "def tanh( input, derivative = False):\n",
    "\tif derivative:\n",
    "\t\treturn 1 - input ** 2\n",
    "\t\n",
    "\treturn np.tanh( input)\n",
    "\n",
    "def softmax( input):\n",
    "\treturn np.exp( input) / np.sum( np.exp( input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Long Short-Term Memory Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "\tdef __init__( self, input_size, hidden_size, output_size):\n",
    "\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\n",
    "\t\t# Forget Gate\n",
    "\t\tself.wf = initWeight( input_size, hidden_size)\n",
    "\t\tself.bf = np.zeros( ( hidden_size, 1))\n",
    "\n",
    "\t\t# Input Gate\n",
    "\t\tself.wi = initWeight( input_size, hidden_size)\n",
    "\t\tself.bi = np.zeros( ( hidden_size, 1))\n",
    "\n",
    "\t\t# Candidate Gate\n",
    "\t\tself.wc = initWeight( input_size, hidden_size)\n",
    "\t\tself.bc = np.zeros( ( hidden_size, 1))\n",
    "\n",
    "\t\t# Output Gate\n",
    "\t\tself.wo = initWeight( input_size, hidden_size)\n",
    "\t\tself.bo = np.zeros( ( hidden_size, 1))\n",
    "\n",
    "\t\t# Final Gate\n",
    "\t\tself.wy = initWeight( hidden_size, output_size)\n",
    "\t\tself.by = np.zeros( ( output_size, 1))\n",
    "\n",
    "\t# Reset Network Memeory\n",
    "\tdef reset( self):\n",
    "\t\tself.concat_inputs = {}\n",
    "\n",
    "\t\tself.hidden_states = { -1: np.zeros( ( self.hidden_size, 1))}\n",
    "\t\tself.cell_states = { -1: np.zeros( ( self.hidden_size, 1))}\n",
    "\n",
    "\t\tself.activation_outputs = {}\n",
    "\t\tself.candidate_gates = {}\n",
    "\t\tself.output_gates = {}\n",
    "\t\tself.forget_gates = {}\n",
    "\t\tself.input_gates = {}\n",
    "\t\tself.outputs = {}\n",
    "\n",
    "\t# Forward Propagation\n",
    "\tdef forward( self, inputs):\n",
    "\t\tself.reset()\n",
    "\n",
    "\t\toutputs = []\n",
    "\n",
    "\t\tfor q in range( len( inputs)):\n",
    "\t\t\tself.concat_inputs[ q] = np.concatenate( ( self.hidden_states[ q - 1], inputs[ q]))\n",
    "\n",
    "\t\t\tself.forget_gates[ q] = sigmoid( np.dot( self.wf, self.concat_inputs[ q]) + self.bf)\n",
    "\t\t\tself.input_gates[ q] = sigmoid( np.dot( self.wi, self.concat_inputs[ q]) + self.bi)\n",
    "\t\t\tself.candidate_gates[ q] = tanh( np.dot( self.wc, self.concat_inputs[ q]) + self.bc)\n",
    "\t\t\tself.output_gates[ q] = sigmoid( np.dot( self.wo, self.concat_inputs[ q]) + self.bo)\n",
    "\n",
    "\t\t\tself.cell_states[ q] = self.forget_gates[ q] * self.cell_states[ q - 1] + self.input_gates[ q] * self.candidate_gates[ q]\n",
    "\t\t\tself.hidden_states[ q] = self.output_gates[ q] * tanh( self.cell_states[ q])\n",
    "\n",
    "\t\t\toutputs += [ np.dot( self.wy, self.hidden_states[ q]) + self.by]\n",
    "\n",
    "\t\treturn outputs\n",
    "\t\n",
    "\t# Backward Propagation\n",
    "\tdef backward( self, errors, inputs, learning_rate):\n",
    "\t\td_wf, d_bf = 0, 0\n",
    "\t\td_wi, d_bi = 0, 0\n",
    "\t\td_wc, d_bc = 0, 0\n",
    "\t\td_wo, d_bo = 0, 0\n",
    "\t\td_wy, d_by = 0, 0\n",
    "\n",
    "\t\tdh_next, dc_next = np.zeros_like( self.hidden_states[ 0]), np.zeros_like( self.cell_states[ 0])\n",
    "\t\tfor q in reversed( range( len( inputs))):\n",
    "\n",
    "\t\t\terror = errors[ q]\n",
    "\n",
    "\t\t\t# Final Gates Error\n",
    "\t\t\td_wy += np.dot( error, self.hidden_states[ q].T)\n",
    "\t\t\td_by += error\n",
    "\n",
    "\t\t\t# Hidden State Error\n",
    "\t\t\td_hs = np.dot( self.wy.T, error) + dh_next\n",
    "\n",
    "\t\t\t# Output Gate Weights and Biases Errors\n",
    "\t\t\td_o = tanh( self.cell_states[ q]) * d_hs * sigmoid( self.output_gates[ q], derivative=True)\n",
    "\t\t\td_wo += np.dot( d_o, inputs[ q].T)\n",
    "\t\t\td_bo += d_o\n",
    "\n",
    "\t\t\t# Cell State Error\n",
    "\t\t\td_cs = tanh( tanh( self.cell_states[ q]), derivative=True) * self.output_gates[ q] * d_hs + dc_next\n",
    "\n",
    "\t\t\t# Forget Gate Weights and Biases Errors\n",
    "\t\t\td_f = d_cs * self.cell_states[ q - 1] * sigmoid( self.forget_gates[ q], derivative=True)\n",
    "\t\t\td_wf += np.dot( d_f, inputs[ q].T)\n",
    "\t\t\td_bf += d_f\n",
    "\n",
    "\t\t\t# Input Gate Weights and Biases Error\n",
    "\t\t\td_i = d_cs * self.candidate_gates[ q] * sigmoid( self.input_gates[ q], derivative=True)\n",
    "\t\t\td_wi += np.dot( d_i, inputs[ q].T)\n",
    "\t\t\td_bi += d_i\n",
    "\n",
    "\t\t\t# Candidate Gate Weights and Biases Errors\n",
    "\t\t\td_c = d_cs * self.input_gates[ q] * tanh( self.candidate_gates[ q], derivative=True)\n",
    "\t\t\td_wc += np.dot( d_c, inputs[ q].T)\n",
    "\t\t\td_bc += d_c\n",
    "\n",
    "\t\t\t# Concatenated Input Error ( Sum of Error at Each Gate)\n",
    "\t\t\td_z = np.dot( self.wf.T, d_f) + np.dot( self.wi.T, d_i) + np.dot( self.wc.T, d_c) + np.dot( self.wo.T, d_o)\n",
    "\n",
    "\t\t\t# Error of Hidden State and Cell State at Next TIme Step\n",
    "\t\t\tdh_next = d_z[ :self.hidden_size, :]\n",
    "\t\t\tdc_next = self.forget_gates[ q] * d_cs\n",
    "\n",
    "\t\tfor d_ in ( d_wf, d_bf, d_wi, d_bi, d_wc, d_bc, d_wo, d_bo, d_wy, d_by):\n",
    "\t\t\tnp.clip( d_, -1, 1, out=d_)\n",
    "\n",
    "\t\tself.wf += d_wf * learning_rate\n",
    "\t\tself.bf += d_bf * learning_rate\n",
    "\n",
    "\t\tself.wi += d_wi * learning_rate\n",
    "\t\tself.bi += d_bi * learning_rate\n",
    "\n",
    "\t\tself.wc += d_wc * learning_rate\n",
    "\t\tself.bc += d_bc * learning_rate\n",
    "\n",
    "\t\tself.wo += d_wo * learning_rate\n",
    "\t\tself.bo += d_bo * learning_rate\n",
    "\n",
    "\t\tself.wy += d_wy * learning_rate\n",
    "\t\tself.by += d_by * learning_rate\n",
    "\n",
    "\tdef fit( self, inputs, labels, epochs, learning_rate):\n",
    "\t\tinputs = [ oneHotEncode( input) for input in inputs]\n",
    "\n",
    "\t\tfor _ in tqdm( range( epochs)):\n",
    "\t\t\tpredictions = self.forward( inputs)\n",
    "\n",
    "\t\t\terrors = []\n",
    "\t\t\tfor q in range( len( predictions)):\n",
    "\t\t\t\terrors += [ -softmax( predictions[ q])]\n",
    "\t\t\t\terrors[ -1][ char_to_idx[ labels[ q]]] += 1\n",
    "\n",
    "\t\t\tself.backward( errors, self.concat_inputs, learning_rate)\n",
    "\n",
    "\tdef predict( self, inputs, labels):\n",
    "\t\thit = 0\n",
    "\n",
    "\t\tprobabilities = self.forward( [ oneHotEncode( input) for input in inputs])\n",
    "\n",
    "\t\toutput = \"\"\n",
    "\n",
    "\t\tfor q in range( len( labels)):\n",
    "\t\t\tprediction = idx_to_char[ np.random.choice( [ *range( char_size)], p = softmax( probabilities[ q].reshape( -1)))]\n",
    "\n",
    "\t\t\toutput += prediction\n",
    "\n",
    "\t\t\tif prediction == labels[ q]:\n",
    "\t\t\t\thit += 1\n",
    "\n",
    "\t\tprint( f\"Ground Truth:\\n\\t{ labels}\\n\")\n",
    "\t\tprint( f\"Predictions:\\n\\t{ ''.join( output)}\\n\")\n",
    "\n",
    "\t\tprint( f\"Accuracy: { hit * 100 / len( inputs)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:56<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth:\n",
      "\to be, or not to be, that is the question: whether 'tis nobler in the mind to suffer the slings and arrows of outrageous fortune, or to take arms against a sea of troubles and by opposing end them. to die—to sleep, no more; and by a sleep to say we end the heart-ache and the thousand natural shocks that flesh is heir to: 'tis a consummation devoutly to be wish'd. to die, to sleep; to sleep, perchance to dream—ay, there's the rub: for in that sleep of death what dreams may come, when we have shuffled off this mortal coil, must give us pause—there's the respect that makes calamity of so long life. for who would bear the whips and scorns of time, th'oppressor's wrong, the proud man's contumely, the pangs of dispriz'd love, the law's delay, the insolence of office, and the spurns that patient merit of th'unworthy takes, when he himself might his quietus make\n",
      "\n",
      "Predictions:\n",
      "\to be, or not to be, that is the question: whether 'tis nobler in the mind to suffer the slings and arrows of outrageous fortune, or to take arms against a sea of troubles and by opposing end them. to die—to sleep, no more; and by a sleep to say we end the heart-ache and the thousand natural shocks that flesh is heir to: 'tis a consummation devoutly to be wish'd. to die, to sleep; to sleep, perchance to dream—ay, there's the rub: for in that sleep of death what dreams may come, when we have shuffled off this mortal coil, must give us pause—there's the respect that makes calamity of so long life. for who would bear the whips and scorns of time, th'oppressor's wrong, the proud man's contumely, the pangs of dispriz'd love, the law's delay, the insolence of office, and the spurns that patient merit of th'unworthy takes, when he himself might his quietus make\n",
      "\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 25\n",
    "\n",
    "lstm = LSTM(\n",
    "\tinput_size=char_size + hidden_size,\n",
    "\thidden_size=hidden_size,\n",
    "\toutput_size=char_size\n",
    ")\n",
    "\n",
    "lstm.fit(\n",
    "\tinputs=train_X,\n",
    "\tlabels=train_y,\n",
    "\tepochs=1000,\n",
    "\tlearning_rate=0.05\n",
    ")\n",
    "\n",
    "lstm.predict(\n",
    "\tinputs=train_X,\n",
    "\tlabels=train_y\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
